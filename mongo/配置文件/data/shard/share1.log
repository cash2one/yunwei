2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten] MongoDB starting : pid=1995 port=27000 dbpath=/data/database/mongo/data/shard 64-bit host=good
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten] db version v3.2.9
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten] git version: 22ec9e93b40c85fc7cae7d56e7d6a02fd811088c
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten] allocator: tcmalloc
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten] modules: none
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten] build environment:
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten]     distmod: rhel62
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten]     distarch: x86_64
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten]     target_arch: x86_64
2016-08-23T05:46:42.355+0800 I CONTROL  [initandlisten] options: { config: "shard/shard1.conf", net: { maxIncomingConnections: 800, port: 27000 }, processManagement: { fork: true }, replication: { replSet: "shard1" }, sharding: { clusterRole: "shardsvr" }, storage: { dbPath: "/data/database/mongo/data/shard", mmapv1: { smallFiles: true } }, systemLog: { destination: "file", logAppend: true, path: "/data/database/mongo/data/shard/share1.log" } }
2016-08-23T05:46:42.370+0800 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=1G,session_max=20000,eviction=(threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),checkpoint=(wait=60,log_size=2GB),statistics_log=(wait=0),
2016-08-23T05:46:42.427+0800 W STORAGE  [initandlisten] Detected configuration for non-active storage engine mmapv1 when current storage engine is wiredTiger
2016-08-23T05:46:42.427+0800 I CONTROL  [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.
2016-08-23T05:46:42.427+0800 I CONTROL  [initandlisten] 
2016-08-23T05:46:42.428+0800 I CONTROL  [initandlisten] 
2016-08-23T05:46:42.428+0800 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2016-08-23T05:46:42.428+0800 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2016-08-23T05:46:42.428+0800 I CONTROL  [initandlisten] 
2016-08-23T05:46:42.428+0800 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'.
2016-08-23T05:46:42.428+0800 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2016-08-23T05:46:42.428+0800 I CONTROL  [initandlisten] 
2016-08-23T05:46:42.442+0800 I REPL     [initandlisten] Did not find local voted for document at startup;  NoMatchingDocument: Did not find replica set lastVote document in local.replset.election
2016-08-23T05:46:42.442+0800 I REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2016-08-23T05:46:42.442+0800 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/database/mongo/data/shard/diagnostic.data'
2016-08-23T05:46:42.443+0800 I NETWORK  [HostnameCanonicalizationWorker] Starting hostname canonicalization worker
2016-08-23T05:46:42.474+0800 I NETWORK  [initandlisten] waiting for connections on port 27000
2016-08-23T05:46:57.464+0800 W NETWORK  [HostnameCanonicalizationWorker] Failed to obtain address information for hostname good: Name or service not known
2016-08-23T05:47:52.885+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:48411 #1 (1 connection now open)
2016-08-23T05:49:18.963+0800 I REPL     [conn1] replSetInitiate admin command received from client
2016-08-23T05:49:18.981+0800 I REPL     [conn1] replSetInitiate config object with 3 members parses ok
2016-08-23T05:49:18.986+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Connecting to 192.168.30.129:27001
2016-08-23T05:49:18.986+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Connecting to 192.168.30.129:27002
2016-08-23T05:49:18.987+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Successfully connected to 192.168.30.129:27001
2016-08-23T05:49:18.988+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Successfully connected to 192.168.30.129:27002
2016-08-23T05:49:18.990+0800 I REPL     [conn1] ******
2016-08-23T05:49:18.990+0800 I REPL     [conn1] creating replication oplog of size: 990MB...
2016-08-23T05:49:18.991+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38586 #2 (2 connections now open)
2016-08-23T05:49:18.992+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38587 #3 (3 connections now open)
2016-08-23T05:49:18.994+0800 I STORAGE  [conn1] Starting WiredTigerRecordStoreThread local.oplog.rs
2016-08-23T05:49:18.994+0800 I STORAGE  [conn1] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2016-08-23T05:49:18.994+0800 I STORAGE  [conn1] Scanning the oplog to determine where to place markers for truncation
2016-08-23T05:49:19.012+0800 I REPL     [conn1] ******
2016-08-23T05:49:19.039+0800 I REPL     [ReplicationExecutor] New replica set config in use: { _id: "shard1", version: 1, protocolVersion: 1, members: [ { _id: 0, host: "192.168.30.129:27000", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "192.168.30.129:27001", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "192.168.30.129:27002", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('57bb735eab8557c668783f7b') } }
2016-08-23T05:49:19.039+0800 I REPL     [ReplicationExecutor] This node is 192.168.30.129:27000 in the config
2016-08-23T05:49:19.039+0800 I REPL     [ReplicationExecutor] transition to STARTUP2
2016-08-23T05:49:19.040+0800 I REPL     [ReplicationExecutor] Member 192.168.30.129:27002 is now in state STARTUP
2016-08-23T05:49:19.040+0800 I REPL     [ReplicationExecutor] Member 192.168.30.129:27001 is now in state STARTUP
2016-08-23T05:49:19.040+0800 I REPL     [conn1] Starting replication applier threads
2016-08-23T05:49:19.042+0800 I REPL     [ReplicationExecutor] transition to RECOVERING
2016-08-23T05:49:19.043+0800 I REPL     [ReplicationExecutor] transition to SECONDARY
2016-08-23T05:49:20.997+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38588 #4 (4 connections now open)
2016-08-23T05:49:20.997+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38589 #5 (5 connections now open)
2016-08-23T05:49:20.998+0800 I NETWORK  [conn5] end connection 192.168.30.129:38589 (4 connections now open)
2016-08-23T05:49:20.999+0800 I NETWORK  [conn4] end connection 192.168.30.129:38588 (3 connections now open)
2016-08-23T05:49:21.101+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38594 #6 (4 connections now open)
2016-08-23T05:49:21.102+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38595 #7 (5 connections now open)
2016-08-23T05:49:21.114+0800 I NETWORK  [conn7] end connection 192.168.30.129:38595 (4 connections now open)
2016-08-23T05:49:21.116+0800 I NETWORK  [conn6] end connection 192.168.30.129:38594 (3 connections now open)
2016-08-23T05:49:24.041+0800 I REPL     [ReplicationExecutor] Member 192.168.30.129:27001 is now in state SECONDARY
2016-08-23T05:49:24.041+0800 I REPL     [ReplicationExecutor] Member 192.168.30.129:27002 is now in state SECONDARY
2016-08-23T05:49:30.445+0800 I REPL     [ReplicationExecutor] Starting an election, since we've seen no PRIMARY in the past 10000ms
2016-08-23T05:49:30.445+0800 I REPL     [ReplicationExecutor] conducting a dry run election to see if we could be elected
2016-08-23T05:49:30.480+0800 I REPL     [ReplicationExecutor] dry election run succeeded, running for election
2016-08-23T05:49:30.512+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Connecting to 192.168.30.129:27002
2016-08-23T05:49:30.513+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Successfully connected to 192.168.30.129:27002
2016-08-23T05:49:30.514+0800 I REPL     [ReplicationExecutor] election succeeded, assuming primary role in term 1
2016-08-23T05:49:30.514+0800 I REPL     [ReplicationExecutor] transition to PRIMARY
2016-08-23T05:49:30.514+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Connecting to 192.168.30.129:27002
2016-08-23T05:49:30.514+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Successfully connected to 192.168.30.129:27002
2016-08-23T05:49:31.052+0800 I REPL     [rsSync] transition to primary complete; database writes are now permitted
2016-08-23T05:49:32.042+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38598 #8 (4 connections now open)
2016-08-23T05:49:32.042+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38599 #9 (5 connections now open)
2016-08-23T05:49:32.043+0800 I NETWORK  [conn8] end connection 192.168.30.129:38598 (4 connections now open)
2016-08-23T05:49:32.044+0800 I NETWORK  [conn9] end connection 192.168.30.129:38599 (3 connections now open)
2016-08-23T05:49:32.044+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38600 #10 (4 connections now open)
2016-08-23T05:49:32.044+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38601 #11 (5 connections now open)
2016-08-23T05:49:32.044+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38602 #12 (6 connections now open)
2016-08-23T05:49:32.045+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38603 #13 (7 connections now open)
2016-08-23T06:09:41.766+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.128:44612 #14 (8 connections now open)
2016-08-23T06:09:41.769+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.128:44613 #15 (9 connections now open)
2016-08-23T06:09:41.775+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.128:44614 #16 (10 connections now open)
2016-08-23T06:09:50.024+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.128:44620 #17 (11 connections now open)
2016-08-23T06:09:50.028+0800 I SHARDING [conn17] remote client 192.168.30.128:44620 initialized this host as shard shard1
2016-08-23T06:09:50.028+0800 I SHARDING [ShardingState initialization] first cluster operation detected, adding sharding hook to enable versioning and authentication to remote servers
2016-08-23T06:09:50.028+0800 I SHARDING [ShardingState initialization] Updating config server connection string to: 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002
2016-08-23T06:09:50.031+0800 I NETWORK  [ShardingState initialization] SyncClusterConnection connecting to [192.168.30.128:27000]
2016-08-23T06:09:50.031+0800 I SHARDING [LockPinger] creating distributed lock ping thread for 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 and process good:27000:1471903790:-937302723 (sleeping for 30000ms)
2016-08-23T06:09:50.031+0800 I NETWORK  [LockPinger] SyncClusterConnection connecting to [192.168.30.128:27000]
2016-08-23T06:09:50.033+0800 I NETWORK  [ShardingState initialization] SyncClusterConnection connecting to [192.168.30.128:27001]
2016-08-23T06:09:50.033+0800 I NETWORK  [LockPinger] SyncClusterConnection connecting to [192.168.30.128:27001]
2016-08-23T06:09:50.034+0800 I NETWORK  [LockPinger] SyncClusterConnection connecting to [192.168.30.128:27002]
2016-08-23T06:09:50.034+0800 I NETWORK  [ShardingState initialization] SyncClusterConnection connecting to [192.168.30.128:27002]
2016-08-23T06:09:50.036+0800 I NETWORK  [ShardingState initialization] Starting new replica set monitor for shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002
2016-08-23T06:09:50.036+0800 I NETWORK  [ReplicaSetMonitorWatcher] starting
2016-08-23T06:09:50.091+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:09:50.035+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:10:00.038+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38636 #18 (12 connections now open)
2016-08-23T06:10:10.082+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38644 #19 (13 connections now open)
2016-08-23T06:10:20.114+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:10:20.092+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:10:41.777+0800 I NETWORK  [conn15] end connection 192.168.30.128:44613 (12 connections now open)
2016-08-23T06:10:50.149+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:10:50.115+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:10:52.842+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.128:44630 #20 (13 connections now open)
2016-08-23T06:10:52.845+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.128:44631 #21 (14 connections now open)
2016-08-23T06:10:52.907+0800 I INDEX    [conn21] build index on: shop.user properties: { v: 1, key: { userid: 1.0 }, name: "userid_1", ns: "shop.user" }
2016-08-23T06:10:52.907+0800 I INDEX    [conn21] 	 building index using bulk method
2016-08-23T06:10:52.907+0800 I INDEX    [conn21] build index done.  scanned 0 total records. 0 secs
2016-08-23T06:10:52.946+0800 I SHARDING [conn17] remotely refreshing metadata for shop.user with requested shard version 1|0||57bb7874e711cb43affe4114, current shard version is 0|0||000000000000000000000000, current metadata version is 0|0||000000000000000000000000
2016-08-23T06:10:52.948+0800 I SHARDING [conn17] collection shop.user was previously unsharded, new metadata loaded with shard version 1|0||57bb7874e711cb43affe4114
2016-08-23T06:10:52.948+0800 I SHARDING [conn17] collection version was loaded at version 1|0||57bb7874e711cb43affe4114, took 1ms
2016-08-23T06:11:20.175+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:11:20.153+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:11:50.195+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:11:50.176+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:12:20.217+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:12:20.196+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:12:50.230+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:12:50.219+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:13:20.248+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:13:20.231+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:13:50.257+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:13:50.248+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:14:20.272+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:14:20.258+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:14:41.776+0800 I NETWORK  [conn16] end connection 192.168.30.128:44614 (13 connections now open)
2016-08-23T06:14:50.294+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:14:50.273+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:15:02.653+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.128:44632 #22 (14 connections now open)
2016-08-23T06:15:02.655+0800 I SHARDING [conn22] received splitChunk request: { splitChunk: "shop.user", keyPattern: { userid: 1.0 }, min: { userid: MinKey }, max: { userid: MaxKey }, from: "shard1", splitKeys: [ { userid: 1000.0 } ], configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", shardVersion: [ Timestamp 1000|0, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') }
2016-08-23T06:15:02.692+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' acquired for 'splitting chunk [{ userid: MinKey }, { userid: MaxKey }) in shop.user', ts : 57bb7966ab8557c668783f7e
2016-08-23T06:15:02.692+0800 I SHARDING [conn22] remotely refreshing metadata for shop.user based on current shard version 1|0||57bb7874e711cb43affe4114, current metadata version is 1|0||57bb7874e711cb43affe4114
2016-08-23T06:15:02.693+0800 I SHARDING [conn22] metadata of collection shop.user already up to date (shard version : 1|0||57bb7874e711cb43affe4114, took 0ms)
2016-08-23T06:15:02.693+0800 I SHARDING [conn22] splitChunk accepted at version 1|0||57bb7874e711cb43affe4114
2016-08-23T06:15:02.706+0800 I NETWORK  [conn22] scoped connection to 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 not being returned to the pool
2016-08-23T06:15:02.706+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:02.706+0800-57bb7966ab8557c668783f7f", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904102706), what: "split", ns: "shop.user", details: { before: { min: { userid: MinKey }, max: { userid: MaxKey } }, left: { min: { userid: MinKey }, max: { userid: 1000.0 }, lastmod: Timestamp 1000|1, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') }, right: { min: { userid: 1000.0 }, max: { userid: MaxKey }, lastmod: Timestamp 1000|2, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') } } }
2016-08-23T06:15:02.712+0800 I NETWORK  [conn22] SyncClusterConnection connecting to [192.168.30.128:27000]
2016-08-23T06:15:02.713+0800 I NETWORK  [conn22] SyncClusterConnection connecting to [192.168.30.128:27001]
2016-08-23T06:15:02.714+0800 I NETWORK  [conn22] SyncClusterConnection connecting to [192.168.30.128:27002]
2016-08-23T06:15:02.745+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' unlocked. 
2016-08-23T06:15:02.746+0800 I SHARDING [conn22] received splitChunk request: { splitChunk: "shop.user", keyPattern: { userid: 1.0 }, min: { userid: 1000.0 }, max: { userid: MaxKey }, from: "shard1", splitKeys: [ { userid: 2000.0 } ], configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", shardVersion: [ Timestamp 1000|2, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') }
2016-08-23T06:15:02.756+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' acquired for 'splitting chunk [{ userid: 1000.0 }, { userid: MaxKey }) in shop.user', ts : 57bb7966ab8557c668783f80
2016-08-23T06:15:02.756+0800 I SHARDING [conn22] remotely refreshing metadata for shop.user based on current shard version 1|2||57bb7874e711cb43affe4114, current metadata version is 1|2||57bb7874e711cb43affe4114
2016-08-23T06:15:02.757+0800 I SHARDING [conn22] metadata of collection shop.user already up to date (shard version : 1|2||57bb7874e711cb43affe4114, took 0ms)
2016-08-23T06:15:02.757+0800 I SHARDING [conn22] splitChunk accepted at version 1|2||57bb7874e711cb43affe4114
2016-08-23T06:15:02.762+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:02.762+0800-57bb7966ab8557c668783f81", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904102762), what: "split", ns: "shop.user", details: { before: { min: { userid: 1000.0 }, max: { userid: MaxKey } }, left: { min: { userid: 1000.0 }, max: { userid: 2000.0 }, lastmod: Timestamp 1000|3, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') }, right: { min: { userid: 2000.0 }, max: { userid: MaxKey }, lastmod: Timestamp 1000|4, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') } } }
2016-08-23T06:15:02.769+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' unlocked. 
2016-08-23T06:15:02.770+0800 I SHARDING [conn22] received splitChunk request: { splitChunk: "shop.user", keyPattern: { userid: 1.0 }, min: { userid: 2000.0 }, max: { userid: MaxKey }, from: "shard1", splitKeys: [ { userid: 3000.0 } ], configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", shardVersion: [ Timestamp 1000|4, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') }
2016-08-23T06:15:02.782+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' acquired for 'splitting chunk [{ userid: 2000.0 }, { userid: MaxKey }) in shop.user', ts : 57bb7966ab8557c668783f82
2016-08-23T06:15:02.782+0800 I SHARDING [conn22] remotely refreshing metadata for shop.user based on current shard version 1|4||57bb7874e711cb43affe4114, current metadata version is 1|4||57bb7874e711cb43affe4114
2016-08-23T06:15:02.783+0800 I SHARDING [conn22] metadata of collection shop.user already up to date (shard version : 1|4||57bb7874e711cb43affe4114, took 0ms)
2016-08-23T06:15:02.783+0800 I SHARDING [conn22] splitChunk accepted at version 1|4||57bb7874e711cb43affe4114
2016-08-23T06:15:02.788+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:02.787+0800-57bb7966ab8557c668783f83", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904102787), what: "split", ns: "shop.user", details: { before: { min: { userid: 2000.0 }, max: { userid: MaxKey } }, left: { min: { userid: 2000.0 }, max: { userid: 3000.0 }, lastmod: Timestamp 1000|5, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') }, right: { min: { userid: 3000.0 }, max: { userid: MaxKey }, lastmod: Timestamp 1000|6, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') } } }
2016-08-23T06:15:02.795+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' unlocked. 
2016-08-23T06:15:02.796+0800 I SHARDING [conn22] received splitChunk request: { splitChunk: "shop.user", keyPattern: { userid: 1.0 }, min: { userid: 3000.0 }, max: { userid: MaxKey }, from: "shard1", splitKeys: [ { userid: 4000.0 } ], configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", shardVersion: [ Timestamp 1000|6, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') }
2016-08-23T06:15:02.804+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' acquired for 'splitting chunk [{ userid: 3000.0 }, { userid: MaxKey }) in shop.user', ts : 57bb7966ab8557c668783f84
2016-08-23T06:15:02.804+0800 I SHARDING [conn22] remotely refreshing metadata for shop.user based on current shard version 1|6||57bb7874e711cb43affe4114, current metadata version is 1|6||57bb7874e711cb43affe4114
2016-08-23T06:15:02.805+0800 I SHARDING [conn22] metadata of collection shop.user already up to date (shard version : 1|6||57bb7874e711cb43affe4114, took 0ms)
2016-08-23T06:15:02.805+0800 I SHARDING [conn22] splitChunk accepted at version 1|6||57bb7874e711cb43affe4114
2016-08-23T06:15:02.811+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:02.811+0800-57bb7966ab8557c668783f85", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904102811), what: "split", ns: "shop.user", details: { before: { min: { userid: 3000.0 }, max: { userid: MaxKey } }, left: { min: { userid: 3000.0 }, max: { userid: 4000.0 }, lastmod: Timestamp 1000|7, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') }, right: { min: { userid: 4000.0 }, max: { userid: MaxKey }, lastmod: Timestamp 1000|8, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') } } }
2016-08-23T06:15:02.819+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' unlocked. 
2016-08-23T06:15:10.998+0800 I NETWORK  [conn22] Starting new replica set monitor for shard2/192.168.30.129:28000,192.168.30.129:28001,192.168.30.129:28002
2016-08-23T06:15:10.998+0800 I SHARDING [conn22] received moveChunk request: { moveChunk: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", to: "shard2/192.168.30.129:28000,192.168.30.129:28001,192.168.30.129:28002", fromShard: "shard1", toShard: "shard2", min: { userid: MinKey }, max: { userid: 1000.0 }, maxChunkSizeBytes: 5242880, configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", secondaryThrottle: true, waitForDelete: false, maxTimeMS: 0, shardVersion: [ Timestamp 1000|8, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') }
2016-08-23T06:15:11.020+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' acquired for 'migrating chunk [{ userid: MinKey }, { userid: 1000.0 }) in shop.user', ts : 57bb796eab8557c668783f86
2016-08-23T06:15:11.020+0800 I SHARDING [conn22] remotely refreshing metadata for shop.user based on current shard version 1|8||57bb7874e711cb43affe4114, current metadata version is 1|8||57bb7874e711cb43affe4114
2016-08-23T06:15:11.022+0800 I SHARDING [conn22] metadata of collection shop.user already up to date (shard version : 1|8||57bb7874e711cb43affe4114, took 1ms)
2016-08-23T06:15:11.022+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:11.022+0800-57bb796fab8557c668783f87", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904111022), what: "moveChunk.start", ns: "shop.user", details: { min: { userid: MinKey }, max: { userid: 1000.0 }, from: "shard1", to: "shard2" } }
2016-08-23T06:15:11.025+0800 I SHARDING [conn22] moveChunk request accepted at version 1|8||57bb7874e711cb43affe4114
2016-08-23T06:15:11.026+0800 I SHARDING [conn22] moveChunk number of documents: 0
2016-08-23T06:15:11.028+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38661 #23 (15 connections now open)
2016-08-23T06:15:11.031+0800 I SHARDING [conn22] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb796fab8557c668783f88", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: MinKey }, max: { userid: 1000.0 }, shardKeyPattern: { userid: 1.0 }, state: "ready", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:15:11.035+0800 I SHARDING [conn22] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb796fab8557c668783f88", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: MinKey }, max: { userid: 1000.0 }, shardKeyPattern: { userid: 1.0 }, state: "ready", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:15:11.040+0800 I SHARDING [conn22] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb796fab8557c668783f88", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: MinKey }, max: { userid: 1000.0 }, shardKeyPattern: { userid: 1.0 }, state: "ready", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:15:11.057+0800 I SHARDING [conn22] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb796fab8557c668783f88", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: MinKey }, max: { userid: 1000.0 }, shardKeyPattern: { userid: 1.0 }, state: "ready", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:15:11.076+0800 I SHARDING [conn22] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb796fab8557c668783f88", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: MinKey }, max: { userid: 1000.0 }, shardKeyPattern: { userid: 1.0 }, state: "ready", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:15:11.109+0800 I SHARDING [conn22] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb796fab8557c668783f88", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: MinKey }, max: { userid: 1000.0 }, shardKeyPattern: { userid: 1.0 }, state: "ready", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:15:11.174+0800 I SHARDING [conn22] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb796fab8557c668783f88", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: MinKey }, max: { userid: 1000.0 }, shardKeyPattern: { userid: 1.0 }, state: "steady", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:15:11.174+0800 I SHARDING [conn22] About to check if it is safe to enter critical section
2016-08-23T06:15:11.175+0800 I SHARDING [conn22] About to enter migrate critical section
2016-08-23T06:15:11.176+0800 I SHARDING [conn22] moveChunk setting version to: 2|0||57bb7874e711cb43affe4114
2016-08-23T06:15:11.210+0800 I SHARDING [conn22] moveChunk migrate commit accepted by TO-shard: { active: false, ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: MinKey }, max: { userid: 1000.0 }, shardKeyPattern: { userid: 1.0 }, state: "done", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 }
2016-08-23T06:15:11.210+0800 I SHARDING [conn22] moveChunk updating self version to: 2|1||57bb7874e711cb43affe4114 through { userid: 1000.0 } -> { userid: 2000.0 } for collection 'shop.user'
2016-08-23T06:15:11.228+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:11.228+0800-57bb796fab8557c668783f89", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904111228), what: "moveChunk.commit", ns: "shop.user", details: { min: { userid: MinKey }, max: { userid: 1000.0 }, from: "shard1", to: "shard2", cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 } }
2016-08-23T06:15:11.230+0800 I SHARDING [conn22] MigrateFromStatus::done About to acquire global lock to exit critical section
2016-08-23T06:15:11.230+0800 I SHARDING [conn22] forking for cleanup of chunk data
2016-08-23T06:15:11.230+0800 I SHARDING [RangeDeleter] Deleter starting delete for: shop.user from { userid: MinKey } -> { userid: 1000.0 }, with opId: 8798
2016-08-23T06:15:11.230+0800 I SHARDING [RangeDeleter] Helpers::removeRangeUnlocked time spent waiting for replication: 0ms
2016-08-23T06:15:11.230+0800 I SHARDING [RangeDeleter] rangeDeleter deleted 0 documents for shop.user from { userid: MinKey } -> { userid: 1000.0 }
2016-08-23T06:15:11.230+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:11.230+0800-57bb796fab8557c668783f8a", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904111230), what: "moveChunk.from", ns: "shop.user", details: { min: { userid: MinKey }, max: { userid: 1000.0 }, step 1 of 6: 0, step 2 of 6: 27, step 3 of 6: 2, step 4 of 6: 146, step 5 of 6: 55, step 6 of 6: 0, to: "shard2", from: "shard1", note: "success" } }
2016-08-23T06:15:11.255+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' unlocked. 
2016-08-23T06:15:11.255+0800 I COMMAND  [conn22] command admin.$cmd command: moveChunk { moveChunk: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", to: "shard2/192.168.30.129:28000,192.168.30.129:28001,192.168.30.129:28002", fromShard: "shard1", toShard: "shard2", min: { userid: MinKey }, max: { userid: 1000.0 }, maxChunkSizeBytes: 5242880, configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", secondaryThrottle: true, waitForDelete: false, maxTimeMS: 0, shardVersion: [ Timestamp 1000|8, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') } keyUpdates:0 writeConflicts:0 numYields:0 reslen:134 locks:{ Global: { acquireCount: { r: 8, w: 2, R: 2 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { r: 2, W: 2 } } } protocol:op_command 257ms
2016-08-23T06:15:12.315+0800 I SHARDING [conn22] received moveChunk request: { moveChunk: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", to: "shard2/192.168.30.129:28000,192.168.30.129:28001,192.168.30.129:28002", fromShard: "shard1", toShard: "shard2", min: { userid: 1000.0 }, max: { userid: 2000.0 }, maxChunkSizeBytes: 5242880, configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", secondaryThrottle: true, waitForDelete: false, maxTimeMS: 0, shardVersion: [ Timestamp 2000|1, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') }
2016-08-23T06:15:12.332+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' acquired for 'migrating chunk [{ userid: 1000.0 }, { userid: 2000.0 }) in shop.user', ts : 57bb7970ab8557c668783f8b
2016-08-23T06:15:12.332+0800 I SHARDING [conn22] remotely refreshing metadata for shop.user based on current shard version 2|0||57bb7874e711cb43affe4114, current metadata version is 2|0||57bb7874e711cb43affe4114
2016-08-23T06:15:12.333+0800 I SHARDING [conn22] updating metadata for shop.user from shard version 2|0||57bb7874e711cb43affe4114 to shard version 2|1||57bb7874e711cb43affe4114
2016-08-23T06:15:12.333+0800 I SHARDING [conn22] collection version was loaded at version 2|1||57bb7874e711cb43affe4114, took 0ms
2016-08-23T06:15:12.333+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:12.333+0800-57bb7970ab8557c668783f8c", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904112333), what: "moveChunk.start", ns: "shop.user", details: { min: { userid: 1000.0 }, max: { userid: 2000.0 }, from: "shard1", to: "shard2" } }
2016-08-23T06:15:12.337+0800 I SHARDING [conn22] moveChunk request accepted at version 2|1||57bb7874e711cb43affe4114
2016-08-23T06:15:12.338+0800 I SHARDING [conn22] moveChunk number of documents: 0
2016-08-23T06:15:12.342+0800 I SHARDING [conn22] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb7970ab8557c668783f8d", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: 1000.0 }, max: { userid: 2000.0 }, shardKeyPattern: { userid: 1.0 }, state: "steady", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:15:12.342+0800 I SHARDING [conn22] About to check if it is safe to enter critical section
2016-08-23T06:15:12.342+0800 I SHARDING [conn22] About to enter migrate critical section
2016-08-23T06:15:12.343+0800 I SHARDING [conn22] moveChunk setting version to: 3|0||57bb7874e711cb43affe4114
2016-08-23T06:15:12.357+0800 I SHARDING [conn22] moveChunk migrate commit accepted by TO-shard: { active: false, ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: 1000.0 }, max: { userid: 2000.0 }, shardKeyPattern: { userid: 1.0 }, state: "done", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 }
2016-08-23T06:15:12.357+0800 I SHARDING [conn22] moveChunk updating self version to: 3|1||57bb7874e711cb43affe4114 through { userid: 2000.0 } -> { userid: 3000.0 } for collection 'shop.user'
2016-08-23T06:15:12.374+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:12.374+0800-57bb7970ab8557c668783f8e", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904112374), what: "moveChunk.commit", ns: "shop.user", details: { min: { userid: 1000.0 }, max: { userid: 2000.0 }, from: "shard1", to: "shard2", cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 } }
2016-08-23T06:15:12.375+0800 I SHARDING [conn22] MigrateFromStatus::done About to acquire global lock to exit critical section
2016-08-23T06:15:12.376+0800 I SHARDING [conn22] forking for cleanup of chunk data
2016-08-23T06:15:12.376+0800 I SHARDING [RangeDeleter] Deleter starting delete for: shop.user from { userid: 1000.0 } -> { userid: 2000.0 }, with opId: 8814
2016-08-23T06:15:12.376+0800 I SHARDING [RangeDeleter] Helpers::removeRangeUnlocked time spent waiting for replication: 0ms
2016-08-23T06:15:12.376+0800 I SHARDING [RangeDeleter] rangeDeleter deleted 0 documents for shop.user from { userid: 1000.0 } -> { userid: 2000.0 }
2016-08-23T06:15:12.376+0800 I SHARDING [conn22] about to log metadata event into changelog: { _id: "good-2016-08-23T06:15:12.376+0800-57bb7970ab8557c668783f8f", server: "good", clientAddr: "192.168.30.128:44632", time: new Date(1471904112376), what: "moveChunk.from", ns: "shop.user", details: { min: { userid: 1000.0 }, max: { userid: 2000.0 }, step 1 of 6: 0, step 2 of 6: 22, step 3 of 6: 2, step 4 of 6: 1, step 5 of 6: 33, step 6 of 6: 0, to: "shard2", from: "shard1", note: "success" } }
2016-08-23T06:15:12.384+0800 I SHARDING [conn22] distributed lock 'shop.user/good:27000:1471903790:-937302723' unlocked. 
2016-08-23T06:15:20.313+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:15:20.295+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:15:50.324+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:15:50.314+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:16:20.346+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:16:20.325+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:16:37.344+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38670 #24 (16 connections now open)
2016-08-23T06:16:37.361+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38671 #25 (17 connections now open)
2016-08-23T06:16:50.361+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:16:50.346+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:17:11.697+0800 I SHARDING [conn17] request split points lookup for chunk shop.user { : 4000.0 } -->> { : MaxKey }
2016-08-23T06:17:18.489+0800 I SHARDING [conn17] request split points lookup for chunk shop.user { : 4000.0 } -->> { : MaxKey }
2016-08-23T06:17:18.497+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.128:44634 #26 (18 connections now open)
2016-08-23T06:17:18.499+0800 I SHARDING [conn26] received splitChunk request: { splitChunk: "shop.user", keyPattern: { userid: 1.0 }, min: { userid: 4000.0 }, max: { userid: MaxKey }, from: "shard1", splitKeys: [ { userid: 9461.0 }, { userid: 15802.0 } ], configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", shardVersion: [ Timestamp 3000|1, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') }
2016-08-23T06:17:18.510+0800 I SHARDING [conn26] distributed lock 'shop.user/good:27000:1471903790:-937302723' acquired for 'splitting chunk [{ userid: 4000.0 }, { userid: MaxKey }) in shop.user', ts : 57bb79eeab8557c668783f90
2016-08-23T06:17:18.510+0800 I SHARDING [conn26] remotely refreshing metadata for shop.user based on current shard version 3|0||57bb7874e711cb43affe4114, current metadata version is 3|0||57bb7874e711cb43affe4114
2016-08-23T06:17:18.511+0800 I SHARDING [conn26] updating metadata for shop.user from shard version 3|0||57bb7874e711cb43affe4114 to shard version 3|1||57bb7874e711cb43affe4114
2016-08-23T06:17:18.511+0800 I SHARDING [conn26] collection version was loaded at version 3|1||57bb7874e711cb43affe4114, took 0ms
2016-08-23T06:17:18.511+0800 I SHARDING [conn26] splitChunk accepted at version 3|1||57bb7874e711cb43affe4114
2016-08-23T06:17:18.521+0800 I SHARDING [conn26] about to log metadata event into changelog: { _id: "good-2016-08-23T06:17:18.521+0800-57bb79eeab8557c668783f91", server: "good", clientAddr: "192.168.30.128:44634", time: new Date(1471904238521), what: "multi-split", ns: "shop.user", details: { before: { min: { userid: 4000.0 }, max: { userid: MaxKey } }, number: 1, of: 3, chunk: { min: { userid: 4000.0 }, max: { userid: 9461.0 }, lastmod: Timestamp 3000|2, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') } } }
2016-08-23T06:17:18.527+0800 I SHARDING [conn26] about to log metadata event into changelog: { _id: "good-2016-08-23T06:17:18.527+0800-57bb79eeab8557c668783f92", server: "good", clientAddr: "192.168.30.128:44634", time: new Date(1471904238527), what: "multi-split", ns: "shop.user", details: { before: { min: { userid: 4000.0 }, max: { userid: MaxKey } }, number: 2, of: 3, chunk: { min: { userid: 9461.0 }, max: { userid: 15802.0 }, lastmod: Timestamp 3000|3, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') } } }
2016-08-23T06:17:18.537+0800 I SHARDING [conn26] about to log metadata event into changelog: { _id: "good-2016-08-23T06:17:18.537+0800-57bb79eeab8557c668783f93", server: "good", clientAddr: "192.168.30.128:44634", time: new Date(1471904238537), what: "multi-split", ns: "shop.user", details: { before: { min: { userid: 4000.0 }, max: { userid: MaxKey } }, number: 3, of: 3, chunk: { min: { userid: 15802.0 }, max: { userid: MaxKey }, lastmod: Timestamp 3000|4, lastmodEpoch: ObjectId('57bb7874e711cb43affe4114') } } }
2016-08-23T06:17:18.545+0800 I SHARDING [conn26] distributed lock 'shop.user/good:27000:1471903790:-937302723' unlocked. 
2016-08-23T06:17:18.552+0800 I SHARDING [conn26] received moveChunk request: { moveChunk: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", to: "shard2/192.168.30.129:28000,192.168.30.129:28001,192.168.30.129:28002", fromShard: "shard1", toShard: "shard2", min: { userid: 15802.0 }, max: { userid: MaxKey }, maxChunkSizeBytes: 5242880, configdb: "192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002", secondaryThrottle: false, waitForDelete: false, maxTimeMS: 0, shardVersion: [ Timestamp 3000|4, ObjectId('57bb7874e711cb43affe4114') ], epoch: ObjectId('57bb7874e711cb43affe4114') }
2016-08-23T06:17:18.562+0800 I SHARDING [conn26] distributed lock 'shop.user/good:27000:1471903790:-937302723' acquired for 'migrating chunk [{ userid: 15802.0 }, { userid: MaxKey }) in shop.user', ts : 57bb79eeab8557c668783f94
2016-08-23T06:17:18.562+0800 I SHARDING [conn26] remotely refreshing metadata for shop.user based on current shard version 3|4||57bb7874e711cb43affe4114, current metadata version is 3|4||57bb7874e711cb43affe4114
2016-08-23T06:17:18.562+0800 I SHARDING [conn26] metadata of collection shop.user already up to date (shard version : 3|4||57bb7874e711cb43affe4114, took 0ms)
2016-08-23T06:17:18.562+0800 I SHARDING [conn26] about to log metadata event into changelog: { _id: "good-2016-08-23T06:17:18.562+0800-57bb79eeab8557c668783f95", server: "good", clientAddr: "192.168.30.128:44634", time: new Date(1471904238562), what: "moveChunk.start", ns: "shop.user", details: { min: { userid: 15802.0 }, max: { userid: MaxKey }, from: "shard1", to: "shard2" } }
2016-08-23T06:17:18.564+0800 I SHARDING [conn26] moveChunk request accepted at version 3|4||57bb7874e711cb43affe4114
2016-08-23T06:17:18.564+0800 I SHARDING [conn26] moveChunk number of documents: 1
2016-08-23T06:17:18.568+0800 I SHARDING [conn26] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb79eeab8557c668783f96", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: 15802.0 }, max: { userid: MaxKey }, shardKeyPattern: { userid: 1.0 }, state: "clone", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:17:18.571+0800 I SHARDING [conn26] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb79eeab8557c668783f96", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: 15802.0 }, max: { userid: MaxKey }, shardKeyPattern: { userid: 1.0 }, state: "clone", counts: { cloned: 0, clonedBytes: 0, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:17:18.575+0800 I SHARDING [conn26] moveChunk data transfer progress: { active: true, sessionId: "shard1_shard2_57bb79eeab8557c668783f96", ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: 15802.0 }, max: { userid: MaxKey }, shardKeyPattern: { userid: 1.0 }, state: "steady", counts: { cloned: 1, clonedBytes: 120, catchup: 0, steady: 0 }, ok: 1.0 } my mem used: 0
2016-08-23T06:17:18.575+0800 I SHARDING [conn26] About to check if it is safe to enter critical section
2016-08-23T06:17:18.576+0800 I SHARDING [conn26] About to enter migrate critical section
2016-08-23T06:17:18.576+0800 I SHARDING [conn26] moveChunk setting version to: 4|0||57bb7874e711cb43affe4114
2016-08-23T06:17:18.595+0800 I SHARDING [conn26] moveChunk migrate commit accepted by TO-shard: { active: false, ns: "shop.user", from: "shard1/192.168.30.129:27000,192.168.30.129:27001,192.168.30.129:27002", min: { userid: 15802.0 }, max: { userid: MaxKey }, shardKeyPattern: { userid: 1.0 }, state: "done", counts: { cloned: 1, clonedBytes: 120, catchup: 0, steady: 0 }, ok: 1.0 }
2016-08-23T06:17:18.595+0800 I SHARDING [conn26] moveChunk updating self version to: 4|1||57bb7874e711cb43affe4114 through { userid: 2000.0 } -> { userid: 3000.0 } for collection 'shop.user'
2016-08-23T06:17:18.603+0800 I SHARDING [conn26] about to log metadata event into changelog: { _id: "good-2016-08-23T06:17:18.603+0800-57bb79eeab8557c668783f97", server: "good", clientAddr: "192.168.30.128:44634", time: new Date(1471904238603), what: "moveChunk.commit", ns: "shop.user", details: { min: { userid: 15802.0 }, max: { userid: MaxKey }, from: "shard1", to: "shard2", cloned: 1, clonedBytes: 120, catchup: 0, steady: 0 } }
2016-08-23T06:17:18.604+0800 I SHARDING [conn26] MigrateFromStatus::done About to acquire global lock to exit critical section
2016-08-23T06:17:18.604+0800 I SHARDING [conn26] forking for cleanup of chunk data
2016-08-23T06:17:18.604+0800 I SHARDING [RangeDeleter] Deleter starting delete for: shop.user from { userid: 15802.0 } -> { userid: MaxKey }, with opId: 110150
2016-08-23T06:17:18.604+0800 I SHARDING [RangeDeleter] rangeDeleter deleted 1 documents for shop.user from { userid: 15802.0 } -> { userid: MaxKey }
2016-08-23T06:17:18.608+0800 I SHARDING [conn26] about to log metadata event into changelog: { _id: "good-2016-08-23T06:17:18.608+0800-57bb79eeab8557c668783f98", server: "good", clientAddr: "192.168.30.128:44634", time: new Date(1471904238608), what: "moveChunk.from", ns: "shop.user", details: { min: { userid: 15802.0 }, max: { userid: MaxKey }, step 1 of 6: 0, step 2 of 6: 12, step 3 of 6: 2, step 4 of 6: 9, step 5 of 6: 28, step 6 of 6: 3, to: "shard2", from: "shard1", note: "success" } }
2016-08-23T06:17:18.617+0800 I SHARDING [conn26] distributed lock 'shop.user/good:27000:1471903790:-937302723' unlocked. 
2016-08-23T06:17:20.381+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:17:20.361+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:17:38.695+0800 I NETWORK  [conn24] end connection 192.168.30.129:38670 (17 connections now open)
2016-08-23T06:17:39.013+0800 I NETWORK  [conn25] end connection 192.168.30.129:38671 (16 connections now open)
2016-08-23T06:17:50.399+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:17:50.382+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:17:56.066+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38683 #27 (17 connections now open)
2016-08-23T06:17:56.066+0800 I SHARDING [conn27] remotely refreshing metadata for shop.user based on current shard version 4|0||57bb7874e711cb43affe4114, current metadata version is 4|0||57bb7874e711cb43affe4114
2016-08-23T06:17:56.067+0800 I SHARDING [conn27] updating metadata for shop.user from shard version 4|0||57bb7874e711cb43affe4114 to shard version 4|1||57bb7874e711cb43affe4114
2016-08-23T06:17:56.067+0800 I SHARDING [conn27] collection version was loaded at version 4|4||57bb7874e711cb43affe4114, took 1ms
2016-08-23T06:17:56.067+0800 I SHARDING [migrateThread] starting receiving-end of migration of chunk { userid: 28651.0 } -> { userid: MaxKey } for collection shop.user from shard2/192.168.30.129:28000,192.168.30.129:28001,192.168.30.129:28002 at epoch 57bb7874e711cb43affe4114
2016-08-23T06:17:56.068+0800 I SHARDING [migrateThread] Deleter starting delete for: shop.user from { userid: 28651.0 } -> { userid: MaxKey }, with opId: 110375
2016-08-23T06:17:56.068+0800 I SHARDING [migrateThread] rangeDeleter deleted 0 documents for shop.user from { userid: 28651.0 } -> { userid: MaxKey }
2016-08-23T06:17:56.070+0800 I SHARDING [migrateThread] Waiting for replication to catch up before entering critical section
2016-08-23T06:17:56.070+0800 I SHARDING [migrateThread] migrate commit succeeded flushing to secondaries for 'shop.user' { userid: 28651.0 } -> { userid: MaxKey }
2016-08-23T06:17:56.072+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38684 #28 (18 connections now open)
2016-08-23T06:17:56.081+0800 I SHARDING [migrateThread] migrate commit succeeded flushing to secondaries for 'shop.user' { userid: 28651.0 } -> { userid: MaxKey }
2016-08-23T06:17:56.082+0800 I SHARDING [migrateThread] about to log metadata event into changelog: { _id: "good-2016-08-23T06:17:56.082+0800-57bb7a14ab8557c668783f99", server: "good", clientAddr: "", time: new Date(1471904276082), what: "moveChunk.to", ns: "shop.user", details: { min: { userid: 28651.0 }, max: { userid: MaxKey }, step 1 of 5: 0, step 2 of 5: 0, step 3 of 5: 2, step 4 of 5: 0, step 5 of 5: 11, note: "success" } }
2016-08-23T06:17:56.123+0800 I SHARDING [conn21] remotely refreshing metadata for shop.user with requested shard version 5|0||57bb7874e711cb43affe4114 based on current shard version 4|1||57bb7874e711cb43affe4114, current metadata version is 4|4||57bb7874e711cb43affe4114
2016-08-23T06:17:56.123+0800 I SHARDING [conn21] updating metadata for shop.user from shard version 4|1||57bb7874e711cb43affe4114 to shard version 5|0||57bb7874e711cb43affe4114
2016-08-23T06:17:56.123+0800 I SHARDING [conn21] collection version was loaded at version 5|1||57bb7874e711cb43affe4114, took 0ms
2016-08-23T06:17:56.126+0800 I SHARDING [conn17] request split points lookup for chunk shop.user { : 28651.0 } -->> { : MaxKey }
2016-08-23T06:18:00.557+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38688 #29 (19 connections now open)
2016-08-23T06:18:02.684+0800 I SHARDING [conn17] request split points lookup for chunk shop.user { : 28651.0 } -->> { : MaxKey }
2016-08-23T06:18:03.321+0800 I NETWORK  [initandlisten] connection accepted from 192.168.30.129:38689 #30 (20 connections now open)
2016-08-23T06:18:10.873+0800 I SHARDING [conn17] request split points lookup for chunk shop.user { : 28651.0 } -->> { : MaxKey }
2016-08-23T06:18:18.341+0800 I SHARDING [conn17] request split points lookup for chunk shop.user { : 28651.0 } -->> { : MaxKey }
2016-08-23T06:18:20.414+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:18:20.399+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:18:26.130+0800 I SHARDING [conn17] request split points lookup for chunk shop.user { : 28651.0 } -->> { : MaxKey }
2016-08-23T06:18:33.283+0800 I SHARDING [conn17] request split points lookup for chunk shop.user { : 28651.0 } -->> { : MaxKey }
2016-08-23T06:18:50.424+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:18:50.415+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:19:20.443+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:19:20.425+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:19:33.001+0800 I NETWORK  [conn11] end connection 192.168.30.129:38601 (19 connections now open)
2016-08-23T06:19:36.640+0800 I NETWORK  [conn30] end connection 192.168.30.129:38689 (18 connections now open)
2016-08-23T06:19:50.452+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:19:50.443+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:20:20.476+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:20:20.454+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:20:50.502+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:20:50.477+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:21:20.527+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:21:20.502+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:21:50.536+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:21:50.527+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:22:20.561+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:22:20.537+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
2016-08-23T06:22:50.581+0800 I SHARDING [LockPinger] cluster 192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002 pinged successfully at 2016-08-23T06:22:50.562+0800 by distributed lock pinger '192.168.30.128:27000,192.168.30.128:27001,192.168.30.128:27002/good:27000:1471903790:-937302723', sleeping for 30000ms
